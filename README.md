# tensorflow2-NetVLAD
NetVLAD in Tensorflow 2.0 for Deep Image Retrieval. Trained on Oxford5k/Paris6k using triplet loss.

## Table of Contents
- [Introduction](#introduction)
- [Data](#data)
- [Loss function](#loss-function)
- [Deep Learning Architecture](#deep-learning-architecture)
- [Metrics](#metrics)
- [Hyperparameters](#hyperparameters)
- [Data Augmentations](#data-augmentations)
- [Setup and Usage](#setup-and-usage)
- [Results](#results)
   - [Paris Dataset](#paris-dataset)
   - [Oxford Dataset](#oxford-dataset)
   - [t-SNE Plots](#t-sne-plots)
- [Result Graphs](#result-graphs)
   - [Paris Dataset](#training-and-validation-loss-curve-of-paris)
   - [Oxford Dataset](#training-and-validation-loss-curve-of-oxford)
   
## Introduction
Goal of this project is to construct a NetVLAD model in Tensorflow 2 for end-to-end learning of deep image retrieval. Images are learnt as embeddings and then ranked according to shortest euclidean distance. 

## Data
The popular [Paris](http://www.robots.ox.ac.uk/~vgg/data/parisbuildings/) and [Oxford](http://www.robots.ox.ac.uk/~vgg/data/oxbuildings/) datsets for image retrieval were used. The provided ROI bounding boxes were not used. Additionally, groundtruth files for hard negative images (received from the Google Drive link in [Github Page](https://github.com/keshik6/deep-image-retrieval)) can be used for negative generation.

Data was split into 80:20 for training and validation.

## Loss Function
The loss function used is triplet loss with a margin, where the triplets are generated by simple offline mining.

The negative image used for any query and positive image was a positive image of a different building, as such buildings would tend to have similar-looking features that we would want our model to be able to differentiate.

## Deep Learning Architecture
The NetVLAD layer, originally designed using MatLab ([Github Page](https://github.com/Relja/netvlad)), was modified to be a custom keras layer compatible with Tensorflow 2 ([Github Page](https://github.com/crlz182/Netvlad-Keras)). The layer is then joined to the VGG16 model with its Fully-Connected layers removed, and weights pre-trained on ImageNet.

Only the weights in the NetVLAD layer are trained, but there is an option to allow for the conv5 layer of the VGG model to be trained.

![Image of Model](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/model.png)

## Metrics
Mean Average Precision (mAP) over all querys were used, where images labelled "ok" and "good" were treated as positives and images labelled "junk" were entirely removed from the calculation.

An alternative method of calculating mAP was also tested, that considered junk images as "semi-positives".         
If a junk image was ranked to be closer in similarity to the query compared to positives, it would contribute towards the mAP but at a reduced value. This value is low if the junk image was ranked to be closer than many positives (effectively treating it like a negative), but increases as more positives are ranked before the junk image, until all positives have been ranked.                 
After this threshold has been reached, all remaining junk images would be considered full positives, with the intention that the model should rank these junk images closer than negative images.

A model swap was also performed, where the model trained on Paris was used to evaluate Oxford and vice-versa. This is to investigate the generalizability of the model.

## Hyperparameters
Object | Value
 --- | --- 
 Image size | (224, 224, 3)
 Batch size | 20 (Parameters updated every 16 triplets)
 Epoch | 200 (Maximum mAP tends to be achieved before 200) 
 Loss Margin | 0.1
 Optimizer | Stochastic Gradient Descent 
 Learning Rate Scheduler | Cosine Decay with Restarts 
 Initial Learning Rate | 1.0e-3 
 Minimum Learning Rate | 1.0e-4 
 Length of each decay period | 10 epochs 
 Subsequent initial learning rates | 0.8x of previous period's initial 
 
 ![Chart of LR for each epoch](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/lr_chart.png)

## Data Augmentations
Standard augmentations were used. These include: 
- Photometric augmentations like brightness, contrast, and saturation
- Geometric augmentations like zoom, rotation, and translation

Prior to augmentation, non-square images were cropped into squares to preserve aspect ratio.

## Setup and Usage
Change the variables in main.py, ensure all paths to the image folder and ground truths are set correctly, then run main.py.

## Results

### **Paris Dataset**
mAP | Ignore Junk | Semipositive Junk | Remarks
--- | --- | --- | ---
**NetVLAD Paper - Trained on Pittsburgh** | 78.5% | - | -
**Ours** | 88.2% | 57.9% | Trained on 80-20 split
**Ours*** | 59.1% | 39.7% | Model swap - Trained on 80-20 split of *Oxford* images
**Ours** | 89.7% | 62.3% | Trained on 80-20 split using hard negative groundtruths
**Ours*** | 57.9% | 38.7% | Model swap - Trained on 80-20 split of *Oxford* images using hard negative groundtruths

### **Oxford Dataset**
mAP | Ignore Junk | Semipositive Junk | Remarks
--- | --- | --- | ---
**NetVLAD Paper - Trained on Pittsburgh** | 69.1% | - | -
**Ours** | 76.5% | 49.7% | Trained on 80-20 split
**Ours*** | 41.6% | 32.5% | Model swap - Trained on 80-20 split of *Paris* images
**Ours** | 79.2% | 61.0% | Trained on 80-20 split using hard negative groundtruths
**Ours*** | 40.0% | 31.5% | Model swap - Trained on 80-20 split of *Paris* images using hard negative groundtruths

The use of hard negatives increases mAP results slightly when tested on the same dataset it was trained on, but does not help the model's generalizability.

### **t-SNE Plots**
![Oxford t-SNE Plot](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/oxfordtsne_labelled_256_5000.png)
![Paris t-SNE Plot](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/paristsne_labelled_256_5000.png)


### **Combined Dataset**
mAP | Ignore Junk | Semipositive Junk | Remarks
--- | --- | --- | ---
**Ours - Augmented** | 75.7% | 54.9% | Trained on 80-20 split of both Paris and Oxford

## Result Graphs

### **Training and Validation Loss Curve of Paris**
Due to interruptions in training, it had to be restarted from checkpoints. As such, the complete curves are made from the curves of three logs.

![Paris Training Loss](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/paris_trainloss.png)
![Paris Validation Loss](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/paris_validloss.png)

### **mAP of model (Augmented Paris Images)**
![Paris mAP](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/paris_map.png)

### **Training and Validation Loss Curve of Oxford**
![Oxford Training Loss](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/oxford_trainloss.png)
![Oxford Validation Loss](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/oxford_validloss.png)

### **mAP of model (Augmented Oxford Images)**
![Oxford mAP](https://github.com/NHGJem/tensorflow2-NetVLAD/blob/master/readme_images/oxford_map.png)
